{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counter Strikle Webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ DaniÃ«l Vermaas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes liquidpedia (https://liquipedia.net/counterstrike/Main_Page), in order to make counter strikle (https://blast.tv/counter-strikle) puzzle-solving easier. Before using the notebook, please read the Liquidpedia ToS about API usage: https://liquipedia.net/api-terms-of-use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import mwparserfromhell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "#from urllib.request import quote\n",
    "\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\"User-Agent\": \"Counter-Strikle-Bot\",\"Accept-Encoding\": \"gzip\"}\n",
    "BASE_URL = \"https://liquipedia.net/counterstrike/api.php?\"\n",
    "REGIONS = {\"Europe\" : [\"Europe\", \"CIS\"], \"Americas\" : [\"Americas\"],\n",
    "           \"Asia-Pacific\" : [\"Oceania\", \"Eastern_%26_Southern_Asia\"]}\n",
    "CSV_FILE = \"players.csv\"\n",
    "COLUMNS = [\"NAME\", \"REAL NAME\", \"REGION\", \"NATIONALITY\", \"TEAM\", \"AGE\", \"WEAPON\", \n",
    "           \"MAJOR APPEARANCES\", \"EARNINGS\", \"LAST UPDATED\"]\n",
    "MISLABELS = [\"Kazakhstan\", \"Turkey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DreamHack/2013/Winter',\n",
       " 'ESL/Major_Series_One/2014/Katowice',\n",
       " 'ESL/One/2014/Cologne',\n",
       " 'DreamHack/2014/Winter',\n",
       " 'ESL/One/2015/Katowice',\n",
       " 'ESL/One/2015/Cologne',\n",
       " 'DreamHack/2015/Cluj-Napoca',\n",
       " 'MLG/2016/Columbus',\n",
       " 'ESL/One/2016/Cologne',\n",
       " 'ELEAGUE/2017/Major',\n",
       " 'PGL/2017/Krakow',\n",
       " 'ELEAGUE/2018/Major',\n",
       " 'FACEIT/2018/Major',\n",
       " 'Intel_Extreme_Masters/Season_XIII/World_Championship',\n",
       " 'StarLadder/2019/Major',\n",
       " 'PGL/2021/Stockholm',\n",
       " 'PGL/2022/Antwerp',\n",
       " 'Intel_Extreme_Masters/2022/Rio']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API call function\n",
    "def fetch_page(page, cooldown=0):\n",
    "    url =  f\"{BASE_URL}action=parse&format=json&page={page}\"\n",
    "    response = requests.get(url, HEADERS)\n",
    "    page_html = response.json()['parse']['text']['*']\n",
    "    soup = BeautifulSoup(page_html,features=\"lxml\")\n",
    "    time.sleep(cooldown)\n",
    "    return soup\n",
    "\n",
    "def query_page(page, cooldown=0):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": player_id,\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"rvsection\":0\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    page_id = next(iter(pages))\n",
    "    page = pages[page_id]\n",
    "    wikicode = mwparserfromhell.parse(page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"])\n",
    "    return wikicode\n",
    "\n",
    "\n",
    "# Fetches all player data and puts it in dict\n",
    "def fetch_player_dict(player_id):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": player_id,\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"rvsection\":0\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    page_id = next(iter(pages))\n",
    "    page = pages[page_id]\n",
    "\n",
    "    wikicode = mwparserfromhell.parse(page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"])\n",
    "    infobox = wikicode.filter_templates(matches=\"Infobox player\")[0]\n",
    "    \n",
    "    infobox_dict = {}\n",
    "    for param in infobox.params:\n",
    "        value = mwparserfromhell.parse(param.value.strip_code()).strip()\n",
    "        infobox_dict[param.name.strip()] = str(value)\n",
    "    return infobox_dict\n",
    "\n",
    "# Fetches list of all concluded majors (checks hltv awards) \n",
    "def fetch_majors():\n",
    "    url = \"https://liquipedia.net/counterstrike/api.php?action=query&prop=revisions&titles=Majors&rvslots=*&rvprop=content&rvsection=8&format=json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    page_id = next(iter(pages))\n",
    "    page = pages[page_id]\n",
    "\n",
    "    wikicode = mwparserfromhell.parse(page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"])\n",
    "    links = wikicode.filter_wikilinks()\n",
    "    links = [link.split('|')[0].replace('[[', '') for link in links]\n",
    "    return links\n",
    "\n",
    "# Fetches all player ids/subdirectories for a given region\n",
    "def fetch_ids(region):\n",
    "    page = fetch_page(f\"Portal:Players/{region}\")\n",
    "    elements = [item.find_all(\"a\")[1] for item in page.find_all(\"td\")]\n",
    "    name_dict = [element[\"title\"].replace(\" \",\"_\") for element in elements]\n",
    "    return name_dict\n",
    "\n",
    "# Fetches all player ids\n",
    "def fetch_players():\n",
    "    url = f'{BASE_URL}action=query&list=categorymembers&cmtitle=Category:Players&cmlimit=max&format=json'\n",
    "    results = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        data = json.loads(response.text)\n",
    "        pages = data['query']['categorymembers']\n",
    "        results.extend(pages)\n",
    "\n",
    "        if 'continue' not in data:\n",
    "            break\n",
    "\n",
    "        cont = data['continue']\n",
    "        cmcontinue = cont['cmcontinue']\n",
    "        url = f\"{url}&cmcontinue={cmcontinue}\"\n",
    "    return results\n",
    "\n",
    "#fetch_player_dict(\"S1mple\")\n",
    "fetch_majors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_major_players():\n",
    "    major_dict = {}\n",
    "    for major in fetch_majors():\n",
    "        url = f\"{BASE_URL}action=query&prop=revisions&titles=PGL/2021/Stockholm&rvslots=*&rvprop=content&format=json\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        pages = data[\"query\"][\"pages\"]\n",
    "        page_id = next(iter(pages))\n",
    "        page = pages[page_id]\n",
    "\n",
    "        wikicode = mwparserfromhell.parse(page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"])\n",
    "\n",
    "        #for template in wikicode.filter_templates(matches=r\"\\bTeamCard\\b\"):\n",
    "        for template in wikicode.filter_templates(matches=r\"^TeamCard\"):\n",
    "            print(\"TITLE:\", list(template.name.strip()))\n",
    "            print(template)\n",
    "            print()\n",
    "\n",
    "        teams_dict = {}\n",
    "        for template in wikicode.filter_templates(matches=r\"\\bTeamCard\\b\"):\n",
    "            if template.name.strip() == \"TeamCard\":\n",
    "                # skip showmatches\n",
    "                if not template.has(\"qualifier\"):\n",
    "                    continue\n",
    "\n",
    "                team = template.get(\"team\").value.strip()\n",
    "                players = [template.get(f\"p{i}\").value.strip() for i in range(1, 6)]\n",
    "                major_dict[team] = players\n",
    "        major_dict[major] = teams_dict\n",
    "\n",
    "major_players = fetch_major_players()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ninjas in Pyjamas': ['REZ', 'Plopski', 'hampus', 'device', 'LNZ'],\n",
       " 'Team Vitality': ['apEX', 'ZywOo', 'shox', 'misutaaa', 'Kyojin'],\n",
       " 'G2 Esports': ['JACKZ', 'AMANEK', 'nexa', 'huNter-', 'NiKo'],\n",
       " 'FURIA Esports': ['yuurih', 'arT', 'VINI', 'KSCERATO', 'drop'],\n",
       " 'Team Liquid': ['EliGE', 'NAF', 'Stewie2K', 'Grim', 'FalleN'],\n",
       " 'Evil Geniuses': ['Brehze', 'CeRq', 'stanislaw', 'oBo', 'MICHU'],\n",
       " 'Natus Vincere': ['s1mple', 'electroNic', 'Boombl4', 'Perfecto', 'b1t'],\n",
       " 'Gambit Esports': ['nafany', 'sh1ro', 'interz', 'Ax1Le', 'HObbit'],\n",
       " 'Astralis': ['dupreeh', 'Xyp9x', 'gla1ve', 'Magisk', 'Lucky'],\n",
       " 'ENCE': ['doto', 'Snappi', 'Spinx', 'dycha', 'hades'],\n",
       " 'BIG': ['tabseN', 'tiziaN', 'syrsoN', 'k1to', 'gade'],\n",
       " 'Movistar Riders': ['mopoz', 'ALEX', 'DeathZz', 'SunPayus', 'dav1g'],\n",
       " 'Heroic': ['stavn', 'cadiaN', 'TeSeS', 'refrezh', 'sjuush'],\n",
       " 'MOUZ': ['ropz', 'frozen', 'Bymas', 'acoR', 'dexter'],\n",
       " 'paiN Gaming': ['PKL', 'biguzera', 'hardzao', 'NEKIZ', 'saffee'],\n",
       " 'Team Spirit': ['sdy', 'chopper', 'mir', 'magixx', 'degster'],\n",
       " 'Copenhagen Flames': ['Jabbi', 'nicoodoz', 'roeJ', 'HooXi', 'Zyphon'],\n",
       " 'FaZe Clan': ['rain', 'olofmeister', 'broky', 'Twistzz', 'karrigan'],\n",
       " 'GODSENT': ['TACO', 'felps', 'latto', 'b4rtiN', 'dumau'],\n",
       " 'Entropiq': ['El1an', 'Lack1', 'NickelBack', 'Krad', 'Forester'],\n",
       " 'Virtus.pro': ['buster', 'Qikert', 'Jame', 'YEKINDAR', 'FL1T'],\n",
       " 'Sharks Esports': ['jnt', 'pancc', 'Lucaozy', 'realziN', 'zevy'],\n",
       " 'TYLOO': ['somebody', 'Summer', 'Attacker', 'SLOWLY', 'DANK1NG'],\n",
       " 'Renegades': ['malta', 'Sico', 'INS', 'Hatz', 'aliStair']}"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"{BASE_URL}action=query&prop=revisions&titles=PGL/2021/Stockholm&rvslots=*&rvprop=content&format=json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "pages = data[\"query\"][\"pages\"]\n",
    "page_id = next(iter(pages))\n",
    "page = pages[page_id]\n",
    "\n",
    "wikicode = mwparserfromhell.parse(page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"])\n",
    "\n",
    "#for template in wikicode.filter_templates(matches=r\"\\bTeamCard\\b\"):\n",
    "for template in wikicode.filter_templates(matches=r\"^TeamCard\"):\n",
    "    print(\"TITLE:\", list(template.name.strip()))\n",
    "    print(template)\n",
    "    print()\n",
    "    \n",
    "major_dict = {}\n",
    "for template in wikicode.filter_templates(matches=r\"\\bTeamCard\\b\"):\n",
    "    if template.name.strip() == \"TeamCard\":\n",
    "        # skip showmatches\n",
    "        if not template.has(\"qualifier\"):\n",
    "            continue\n",
    "        \n",
    "        team = template.get(\"team\").value.strip()\n",
    "        players = [template.get(f\"p{i}\").value.strip() for i in range(1, 6)]\n",
    "        major_dict[team] = players\n",
    "        \n",
    "major_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player-Specific Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME': 'S1mple',\n",
       " 'REGION': 'Ukraine',\n",
       " 'REAL NAME': 'Oleksandr Oleghovych Kostyljev',\n",
       " 'NATIONALITY': 'Ukraine',\n",
       " 'TEAM': 'Natus Vincere',\n",
       " 'AGE': '02/10/1997',\n",
       " 'WEAPON': 'AWP',\n",
       " 'MAJOR APPEARANCES': 0,\n",
       " 'EARNINGS': 1743186,\n",
       " 'LAST UPDATED': '09/04/2023'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_player(player_id, major_list, debug=True):\n",
    "    # parse player information\n",
    "    info_dict = fetch_player_dict(player_id)\n",
    "    if debug:\n",
    "        print(info_dict)\n",
    "    \n",
    "    # add name to dict\n",
    "    output_dict = dict()\n",
    "    output_dict[\"NAME\"] = player_name\n",
    "    output_dict[\"REGION\"] = \"region\"\n",
    "    \n",
    "    # replace name with romanised name if needed\n",
    "    if \"Romanized Name\" in info_dict:\n",
    "        output_dict[\"REAL NAME\"] = info_dict[\"Romanized Name\"]\n",
    "    else:\n",
    "        output_dict[\"REAL NAME\"] = info_dict[\"Name\"]\n",
    "    \n",
    "    # get nationality\n",
    "    if \"Nationality\" in info_dict:\n",
    "        output_dict[\"NATIONALITY\"] = info_dict[\"Nationality\"][1:].split(\"\\xa0\")[0]\n",
    "    \n",
    "    # get team\n",
    "    if \"Team\"  in info_dict:\n",
    "        output_dict[\"TEAM\"] = info_dict[\"Team\"]\n",
    "    \n",
    "    # Get age\n",
    "    if \"Born\" in info_dict:\n",
    "        try:\n",
    "            output_dict[\"AGE\"] = datetime.strptime(info_dict[\"Born\"][:-9].replace(\",\", \"\"), \"%B %d %Y\").strftime(\"%d/%m/%Y\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Get role\n",
    "    role_description = None\n",
    "    if \"Role\" in info_dict:\n",
    "        role_description = info_dict[\"Role\"]\n",
    "    elif \"Roles\" in info_dict:\n",
    "        role_description = info_dict[\"Roles\"]\n",
    "    \n",
    "    if role_description != None:\n",
    "        if \"AWPer\" in role_description:\n",
    "            output_dict[\"WEAPON\"] = \"AWP\"\n",
    "        elif \"Rifler\" in role_description:\n",
    "            output_dict[\"WEAPON\"] = \"AK47\"\n",
    "            \n",
    "            \n",
    "    # Get major appearances\n",
    "    try:\n",
    "        soup = fetch_page(player_name + \"/Results\")\n",
    "        event_elements = soup.find_all(\"tr\", {\"class\": \"valvemajor-highlighted\"})\n",
    "        event_name_list = [event.find(\"td\", {\"style\": \"text-align:left\"}).find(\"a\")[\"href\"] for event in event_elements]\n",
    "        event_name_list = [event for event in event_name_list if event in major_list]\n",
    "        output_dict[\"MAJOR APPEARANCES\"] = len(event_name_list)\n",
    "    except:\n",
    "        output_dict[\"MAJOR APPEARANCES\"] = 0\n",
    "    \n",
    "    if \"Approx. Total Winnings\" in info_dict:\n",
    "        output_dict[\"EARNINGS\"] = int(info_dict[\"Approx. Total Winnings\"].replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "    else:\n",
    "        output_dict[\"EARNINGS\"] = 0\n",
    "    \n",
    "    output_dict[\"LAST UPDATED\"] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    return output_dict\n",
    "\n",
    "#fetch_player(\"XANTARES\", \"Turkey\", MAJOR_LIST, debug=False)\n",
    "fetch_player(\"S1mple\", \"Ukraine\", MAJOR_LIST, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0d5f0697534b0e9e01166630207200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad17bf789b9489283571836c3154cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: list index out of range\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'players.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     playerdata\u001b[38;5;241m.\u001b[39mto_csv(CSV_FILE, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mbuild_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mbuild_df\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mplayerdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3549\u001b[0m )\n\u001b[1;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[1;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'players.csv'"
     ]
    }
   ],
   "source": [
    "def build_df():\n",
    "    # Get dataframe to werite to\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        playerdata = pd.read_csv(CSV_FILE)\n",
    "    else:\n",
    "        playerdata = pd.DataFrame(columns=COLUMNS)\n",
    "        \n",
    "    # Get list of all mayors\n",
    "    major_list = fetch_majors()\n",
    "\n",
    "    try:\n",
    "        for major_region, sub_regions in tqdm(REGIONS.items()):\n",
    "            for sub_region in tqdm(sub_regions, leave=False):\n",
    "                region_ids = fetch_ids(sub_region)[:1]\n",
    "                for player in tqdm(region_ids, leave=False):\n",
    "                    if not (playerdata[\"NAME\"].eq(player)).any():\n",
    "                        row_data = fetch_player(player, major_region, major_list)\n",
    "                        playerdata = pd.concat([playerdata, pd.DataFrame.from_records([row_data])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    \n",
    "    playerdata.to_csv(CSV_FILE, index=False)\n",
    "    return\n",
    "\n",
    "build_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age(birthdate):\n",
    "    birthdate = datetime.strptime(birthdate, \"%d/%m/%Y\")\n",
    "    today = datetime.now()\n",
    "    age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "    return age\n",
    "\n",
    "def playerdata_postprocess(df):\n",
    "    columns = list(pd.read_csv(CSV_FILE).columns)\n",
    "    del columns[columns.index(\"TEAM\")]\n",
    "    df.dropna(inplace = True, subset = columns)\n",
    "    df.sort_values(by=[\"EARNINGS\"], ascending = False, inplace = True)\n",
    "    df[\"AGE\"] = [age(date) for date in df[\"AGE\"]]\n",
    "    df[\"REGION\"] = np.where(df[\"NATIONALITY\"].isin(MISLABELS), \"Europe\", df[\"REGION\"])\n",
    "    return df\n",
    "\n",
    "playerdata_post = playerdata_postprocess(pd.read_csv(CSV_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_selection(data, description):\n",
    "    unique_data = list(data.unique())\n",
    "    return widgets.SelectMultiple(\n",
    "        options=unique_data,\n",
    "        value=unique_data,\n",
    "        rows=len(unique_data),\n",
    "        description=description,\n",
    "        disabled=False)\n",
    "\n",
    "\n",
    "def generate_rangeslider(data, description):\n",
    "    return widgets.FloatRangeSlider(\n",
    "        value=[min(data), max(data)],\n",
    "        min=min(data),\n",
    "        max=max(data),\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='1',\n",
    ")\n",
    "\n",
    "region_selector = generate_selection(playerdata_post[\"REGION\"], \"REGION\")\n",
    "age_slider = generate_rangeslider(playerdata_post[\"AGE\"], \"AGE\")\n",
    "weapon_selector = generate_selection(playerdata_post[\"WEAPON\"], \"WEAPON\")\n",
    "majors_slider = generate_rangeslider(playerdata_post[\"MAJOR APPEARANCES\"], \"MAJOR APPEARANCES\")\n",
    "\n",
    "def ui_selector(sregion, sage, sweapon, smajors):\n",
    "    return playerdata_post.loc[(playerdata_post[\"REGION\"].isin(sregion)) &\n",
    "                               (playerdata_post[\"AGE\"] >= sage[0]) &\n",
    "                               (playerdata_post[\"AGE\"] <= sage[1]) &\n",
    "                               (playerdata_post[\"WEAPON\"].isin(sweapon)) &\n",
    "                               (playerdata_post[\"MAJOR APPEARANCES\"] >= smajors[0]) &\n",
    "                               (playerdata_post[\"MAJOR APPEARANCES\"] <= smajors[1])\n",
    "                               ]\n",
    "    \n",
    "interact(ui_selector, sregion = region_selector, sage = age_slider, sweapon = weapon_selector, smajors = majors_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
