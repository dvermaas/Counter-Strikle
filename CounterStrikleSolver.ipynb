{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counter Strikle Webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Daniël Vermaas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes liquidpedia (https://liquipedia.net/counterstrike/Main_Page), in order to make counter strikle (https://blast.tv/counter-strikle) puzzle-solving easier. Before using the notebook, please read the Liquidpedia ToS about API usage: https://liquipedia.net/api-terms-of-use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import mwparserfromhell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "#from urllib.request import quote\n",
    "\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\"User-Agent\": \"Counter-Strikle-Bot\",\"Accept-Encoding\": \"gzip\"}\n",
    "BASE_URL = \"https://liquipedia.net/counterstrike/api.php?\"\n",
    "QUERY_COOLDOWN = 4\n",
    "CSV_FILE = \"players.csv\"\n",
    "REGIONS = {\n",
    "    \"Europe\" : [\"Europe\", \"CIS\"],\n",
    "    \"Americas\" : [\"North America\", \"South America\"],\n",
    "    \"Asia-Pacific\" : [\"Oceania\", \"Asia\"],\n",
    "}\n",
    "COLUMNS = [\n",
    "    \"NAME\", \n",
    "    \"REAL NAME\", \n",
    "    \"REGION\", \n",
    "    \"NATIONALITY\", \n",
    "    \"TEAM\", \n",
    "    \"AGE\", \n",
    "    \"WEAPON\", \n",
    "    \"MAJOR APPEARANCES\", \n",
    "    \"EARNINGS\", \n",
    "    \"LAST UPDATED\"\n",
    "]\n",
    "UNWANTED_STRINGS = [\n",
    "    \"Players\", \n",
    "    \"Teams\", \n",
    "    \"Tournaments\", \n",
    "    \"Casters\", \n",
    "    \"Countries\", \n",
    "    \"Asia\", \n",
    "    \"CIS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Country to Region Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds country to region dict, and stores it\n",
    "def build_region_dict():\n",
    "    # build the region to country dict\n",
    "    file_name = \"region_country_dict.json\"\n",
    "    if not os.path.exists(file_name):\n",
    "        region_dict = {}\n",
    "        for region, subregions in REGIONS.items():\n",
    "            results = []\n",
    "            for subregion in subregions:\n",
    "                url = f\"{BASE_URL}action=query&list=categorymembers&cmtitle=Category:{subregion}&cmlimit=max&format=json\"\n",
    "                time.sleep(QUERY_COOLDOWN)\n",
    "                response = requests.get(url)\n",
    "                data = json.loads(response.text)\n",
    "                pages = data[\"query\"][\"categorymembers\"]\n",
    "                pages = [line.get(\"title\").split(\":\")[1] for line in pages]\n",
    "                results.extend(pages)\n",
    "            results = [result for result in results if not any(substring in result for substring in UNWANTED_STRINGS)]\n",
    "            region_dict[region] = sorted(list(set(results)))\n",
    "        with open(file_name, \"w\") as file:\n",
    "            json.dump(region_dict, file, indent=2)\n",
    "    \n",
    "    # convert to country to region dict  \n",
    "    with open(file_name, \"r\") as file:\n",
    "        region_dict = json.load(file)\n",
    "    country_region_dict = {}\n",
    "    for region, countries in region_dict.items():\n",
    "        for country in countries:\n",
    "            country_region_dict[country] = region\n",
    "    \n",
    "    return country_region_dict\n",
    "\n",
    "REGION_DICT = build_region_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Azerbaijan',\n",
       " 'Georgia',\n",
       " 'Kazakhstan',\n",
       " 'Kyrgyzstan',\n",
       " 'Tajikistan',\n",
       " 'Turkey',\n",
       " 'Uzbekistan'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_name, \"r\") as file:\n",
    "    region_dict = json.load(file)\n",
    "    \n",
    "set(region_dict[\"Europe\"]) & set(region_dict[\"Asia-Pacific\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Russia',\n",
       " 'Germany',\n",
       " 'Hungary',\n",
       " 'Albania',\n",
       " 'Malta',\n",
       " 'Tajikistan',\n",
       " 'Switzerland',\n",
       " 'Sweden',\n",
       " 'Wales',\n",
       " 'Greece',\n",
       " 'England',\n",
       " 'Portugal',\n",
       " 'Liechtenstein',\n",
       " 'Turkey',\n",
       " 'Kyrgyzstan',\n",
       " 'Austria',\n",
       " 'Scotland',\n",
       " 'Ukraine',\n",
       " 'United Kingdom',\n",
       " 'Uzbekistan',\n",
       " 'Faroe Island',\n",
       " 'Belarus',\n",
       " 'Kazakhstan',\n",
       " 'Belgium',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Ireland',\n",
       " 'Denmark',\n",
       " 'Spain',\n",
       " 'Kosovo',\n",
       " 'Lithuania',\n",
       " 'Montenegro',\n",
       " 'Azerbaijan',\n",
       " 'Norway',\n",
       " 'Croatia',\n",
       " 'Moldova',\n",
       " 'Italy',\n",
       " 'France',\n",
       " 'Bulgaria',\n",
       " 'Poland',\n",
       " 'Romania',\n",
       " 'Armenia',\n",
       " 'North Macedonia',\n",
       " 'Georgia',\n",
       " 'Finland',\n",
       " 'Estonia']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_dict[\"Europe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Germany': 'Europe',\n",
       " 'Hungary': 'Europe',\n",
       " 'Russia': 'Europe',\n",
       " 'Albania': 'Europe',\n",
       " 'Malta': 'Europe',\n",
       " 'Tajikistan': 'Asia-Pacific',\n",
       " 'Switzerland': 'Europe',\n",
       " 'Sweden': 'Europe',\n",
       " 'Wales': 'Europe',\n",
       " 'Greece': 'Europe',\n",
       " 'England': 'Europe',\n",
       " 'Portugal': 'Europe',\n",
       " 'Turkey': 'Asia-Pacific',\n",
       " 'Kyrgyzstan': 'Asia-Pacific',\n",
       " 'Austria': 'Europe',\n",
       " 'Scotland': 'Europe',\n",
       " 'Ukraine': 'Europe',\n",
       " 'United Kingdom': 'Europe',\n",
       " 'Uzbekistan': 'Asia-Pacific',\n",
       " 'Faroe Island': 'Europe',\n",
       " 'Belarus': 'Europe',\n",
       " 'Kazakhstan': 'Asia-Pacific',\n",
       " 'Belgium': 'Europe',\n",
       " 'Bosnia and Herzegovina': 'Europe',\n",
       " 'Ireland': 'Europe',\n",
       " 'Denmark': 'Europe',\n",
       " 'Spain': 'Europe',\n",
       " 'Kosovo': 'Europe',\n",
       " 'Lithuania': 'Europe',\n",
       " 'Montenegro': 'Europe',\n",
       " 'Azerbaijan': 'Asia-Pacific',\n",
       " 'Norway': 'Europe',\n",
       " 'Croatia': 'Europe',\n",
       " 'Moldova': 'Europe',\n",
       " 'Italy': 'Europe',\n",
       " 'France': 'Europe',\n",
       " 'Bulgaria': 'Europe',\n",
       " 'Poland': 'Europe',\n",
       " 'Romania': 'Europe',\n",
       " 'Armenia': 'Europe',\n",
       " 'North Macedonia': 'Europe',\n",
       " 'Georgia': 'Asia-Pacific',\n",
       " 'Finland': 'Europe',\n",
       " 'Estonia': 'Europe',\n",
       " 'Uruguay': 'Americas',\n",
       " 'United States': 'Americas',\n",
       " 'Peru': 'Americas',\n",
       " 'Chile': 'Americas',\n",
       " 'Greenland': 'Americas',\n",
       " 'Venezuela': 'Americas',\n",
       " 'Panama': 'Americas',\n",
       " 'Brazil': 'Americas',\n",
       " 'Guatemala': 'Americas',\n",
       " 'Argentina': 'Americas',\n",
       " 'Ecuador': 'Americas',\n",
       " 'Mexico': 'Americas',\n",
       " 'Paraguay': 'Americas',\n",
       " 'Bolivia': 'Americas',\n",
       " 'Colombia': 'Americas',\n",
       " 'Dominican Republic': 'Americas',\n",
       " 'Curaçao': 'Americas',\n",
       " 'Nicaragua': 'Americas',\n",
       " 'El Salvador': 'Americas',\n",
       " 'Honduras': 'Americas',\n",
       " 'Canada': 'Americas',\n",
       " 'Costa Rica': 'Americas',\n",
       " 'Bahrain': 'Asia-Pacific',\n",
       " 'Nepal': 'Asia-Pacific',\n",
       " 'Cyprus': 'Asia-Pacific',\n",
       " 'Kuwait': 'Asia-Pacific',\n",
       " 'Jordan': 'Asia-Pacific',\n",
       " 'Bangladesh': 'Asia-Pacific',\n",
       " 'India': 'Asia-Pacific',\n",
       " 'Singapore': 'Asia-Pacific',\n",
       " 'Saudi Arabia': 'Asia-Pacific',\n",
       " 'Mongolia': 'Asia-Pacific',\n",
       " 'Afghanistan': 'Asia-Pacific',\n",
       " 'Palestine': 'Asia-Pacific',\n",
       " 'New Zealand': 'Asia-Pacific',\n",
       " 'Brunei': 'Asia-Pacific',\n",
       " 'Pakistan': 'Asia-Pacific',\n",
       " 'Laos': 'Asia-Pacific',\n",
       " 'Turkmenistan': 'Asia-Pacific',\n",
       " 'Japan': 'Asia-Pacific',\n",
       " 'Middle East': 'Asia-Pacific',\n",
       " 'South Korea': 'Asia-Pacific',\n",
       " 'Macau': 'Asia-Pacific',\n",
       " 'Australia': 'Asia-Pacific',\n",
       " 'Hong Kong': 'Asia-Pacific',\n",
       " 'Syria': 'Asia-Pacific',\n",
       " 'China': 'Asia-Pacific',\n",
       " 'Sri Lanka': 'Asia-Pacific',\n",
       " 'Lebanon': 'Asia-Pacific',\n",
       " 'Malaysia': 'Asia-Pacific',\n",
       " 'Myanmar': 'Asia-Pacific',\n",
       " 'Cambodia': 'Asia-Pacific',\n",
       " 'Indonesia': 'Asia-Pacific',\n",
       " 'Taiwan': 'Asia-Pacific',\n",
       " 'Thailand': 'Asia-Pacific',\n",
       " 'Israel': 'Asia-Pacific',\n",
       " 'f': 'l',\n",
       " 'p': 'n',\n",
       " 'm': 'c'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"region_country_dict.json\"\n",
    "with open(file_name, \"r\") as file:\n",
    "    region_dict = json.load(file)\n",
    "for region, countries in region_dict.items():\n",
    "        for country in countries:\n",
    "            country_region_dict[country] = region\n",
    "country_region_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'Israel',\n",
       " 'm': 'Costa Rica',\n",
       " 'e': 'Estonia',\n",
       " 'r': 'Estonia',\n",
       " 'i': 'Israel',\n",
       " 'c': 'Israel',\n",
       " 'a': 'Israel',\n",
       " 's': 'Israel',\n",
       " '-': 'Israel',\n",
       " 'P': 'Israel',\n",
       " 'f': 'Israel',\n",
       " 'E': 'Estonia',\n",
       " 'u': 'Estonia',\n",
       " 'o': 'Estonia',\n",
       " 'p': 'Estonia'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGION_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call function\n",
    "def fetch_page(page, cooldown=0):\n",
    "    url =  f\"{BASE_URL}action=parse&format=json&page={page}\"\n",
    "    response = requests.get(url, HEADERS)\n",
    "    page_html = response.json()['parse']['text']['*']\n",
    "    soup = BeautifulSoup(page_html,features=\"lxml\")\n",
    "    time.sleep(cooldown)\n",
    "    return soup\n",
    "\n",
    "def query_page(page, rvsection, cooldown=QUERY_COOLDOWN):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": page,\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"*\",\n",
    "        \"rvsection\": rvsection,\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    data = response.json()\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    page_id = next(iter(pages))\n",
    "    page = pages[page_id]\n",
    "    wikicode = mwparserfromhell.parse(page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"])\n",
    "    time.sleep(cooldown)\n",
    "    return wikicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches list of all concluded majors (checks hltv awards) \n",
    "def fetch_majors():\n",
    "    wikicode = query_page(\"Majors\", 8)\n",
    "    links = wikicode.filter_wikilinks()\n",
    "    links = [link.split('|')[0].replace('[[', '') for link in links]\n",
    "    return links\n",
    "\n",
    "#fetch_majors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_region_dict = {}\n",
    "unwanted_strings = [\"Players\", \"Teams\", \"Tournaments\", \"Casters\", \"Countries\", \"East Asia\", \"Southeast Asia\", \"CIS\"]\n",
    "for region, countries in region_dict.items():\n",
    "    for country in countries:\n",
    "        if not any(substring in country for substring in unwanted_strings):\n",
    "            country_region_dict[country] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Germany', 'Hungary', 'Russia', 'Albania', 'Malta', 'Tajikistan', 'Switzerland', 'Sweden', 'Wales', 'Greece', 'England', 'Portugal', 'Turkey', 'Kyrgyzstan', 'Austria', 'Scotland', 'Ukraine', 'United Kingdom', 'Uzbekistan', 'Faroe Island', 'Belarus', 'Kazakhstan', 'Belgium', 'Bosnia and Herzegovina', 'Ireland', 'Denmark', 'Spain', 'Kosovo', 'Lithuania', 'Montenegro', 'Azerbaijan', 'Norway', 'Croatia', 'Moldova', 'Italy', 'France', 'Bulgaria', 'Poland', 'Romania', 'Armenia', 'North Macedonia', 'Georgia', 'Finland', 'Estonia', 'Uruguay', 'United States', 'Peru', 'Chile', 'Greenland', 'Venezuela', 'Panama', 'Brazil', 'Guatemala', 'Argentina', 'Ecuador', 'Mexico', 'Paraguay', 'Bolivia', 'Colombia', 'Dominican Republic', 'Curaçao', 'Nicaragua', 'El Salvador', 'Honduras', 'Canada', 'Costa Rica', 'Bahrain', 'Nepal', 'Cyprus', 'Kuwait', 'Jordan', 'Bangladesh', 'India', 'Singapore', 'Saudi Arabia', 'Mongolia', 'Afghanistan', 'Palestine', 'New Zealand', 'Brunei', 'Pakistan', 'Laos', 'Turkmenistan', 'Japan', 'Middle East', 'South Korea', 'Macau', 'Australia', 'Hong Kong', 'Syria', 'China', 'Sri Lanka', 'Lebanon', 'Malaysia', 'Myanmar', 'Cambodia', 'Indonesia', 'Taiwan', 'Thailand', 'Israel'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_region_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Europe'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_region_dict[\"Ukraine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ropz',\n",
       " 'image': 'Ropz at Antwerp Major EU RMR.jpg',\n",
       " 'name': 'Robin Kool',\n",
       " 'birth_date': '1999-12-22',\n",
       " 'country': 'Estonia',\n",
       " 'status': 'Active',\n",
       " 'years_active': '2015 – Present',\n",
       " 'team': 'FaZe Clan',\n",
       " 'role': 'lurk',\n",
       " 'csgo': 'y',\n",
       " 'twitter': 'ropz',\n",
       " 'facebook': 'ropzicle',\n",
       " 'instagram': 'ropzicle',\n",
       " 'youtube': 'c/Ropz',\n",
       " 'twitch': 'ropz',\n",
       " 'esea': '1042223',\n",
       " 'faceit': 'ropz',\n",
       " 'steam': '76561197991272318',\n",
       " 'team_history': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetches all player data and puts it in dict\n",
    "def fetch_player_dict(player_id):\n",
    "    wikicode = query_page(player_id, 0)\n",
    "    infobox = wikicode.filter_templates(matches=\"Infobox player\")[0]\n",
    "    infobox_dict = {}\n",
    "    for param in infobox.params:\n",
    "        value = mwparserfromhell.parse(param.value.strip_code()).strip()\n",
    "        infobox_dict[param.name.strip()] = str(value)\n",
    "    return infobox_dict\n",
    "\n",
    "# Fetches all player ids\n",
    "def fetch_players():\n",
    "    url = f\"{BASE_URL}action=query&list=categorymembers&cmtitle=Category:Players&cmlimit=max&format=json\"\n",
    "    results = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        time.sleep(QUERY_COOLDOWN)\n",
    "        data = json.loads(response.text)\n",
    "        pages = data[\"query\"][\"categorymembers\"]\n",
    "        results.extend(pages)\n",
    "\n",
    "        if \"continue\" not in data:\n",
    "            break\n",
    "\n",
    "        cont = data[\"continue\"]\n",
    "        cmcontinue = cont[\"cmcontinue\"]\n",
    "        url = f\"{url}&cmcontinue={cmcontinue}\"\n",
    "    return results\n",
    "\n",
    "fetch_player_dict(\"ropz\")\n",
    "#fetch_majors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def fetch_major_players():\n",
    "    major_dict = {}\n",
    "    for major in fetch_majors():\n",
    "        wikicode = query_page(major, 6)\n",
    "        teams_dict = {}\n",
    "        for template in wikicode.filter_templates(matches=r\"\\bTeamCard\\b\"):\n",
    "            if template.name.strip() == \"TeamCard\":\n",
    "                # skip showmatches\n",
    "                if not template.has(\"qualifier\"):\n",
    "                    continue\n",
    "                if not template.has(\"p1\"):\n",
    "                    continue\n",
    "                team = template.get(\"team\").value.strip()\n",
    "                players = (template.get(f\"p{i}\").value.strip() for i in range(1, 6))\n",
    "                teams_dict[team] = players\n",
    "        major_dict[major] = teams_dict\n",
    "    return major_dict\n",
    "\n",
    "major_players = fetch_major_players()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ninjas in Pyjamas': ['f0rest', 'GeT_RiGhT', 'Xizt', 'Fifflaren', 'friberg'],\n",
       " 'n!faculty': ['gla1ve', 'karrigan', 'cajunb', 'Pimp', 'raalz'],\n",
       " 'SK Gaming': ['pita', 'twist', 'xelos', 'Delpan', 'MODDII'],\n",
       " 'Copenhagen Wolves': ['FeTiSh', 'dupreeh', 'Xyp9x', 'device', 'Nico'],\n",
       " 'Universal Soldiers': ['TaZ', 'NEO', 'pashaBiceps', 'Snax', 'byali'],\n",
       " 'Natus Vincere': ['Zeus', 'starix', 'ceh9', 'seized', 'kibaken'],\n",
       " 'Astana Dragons': ['ANGE1', 'Dosia', 'AdreN', 'markeloff', 'kUcheR'],\n",
       " 'compLexity Gaming': ['Hiko', 'seang@res', 'Semphis', 'swag', 'n0thing'],\n",
       " 'VeryGames': ['Ex6TenZ', 'NBK-', 'SmithZz', 'ScreaM', 'shox'],\n",
       " 'Clan-Mystik': ['HaRts', 'ioRek', 'kioShiMa', 'KQLY', 'apEX'],\n",
       " 'Fnatic': ['JW', 'flusha', 'schneider', 'Devilwalk', 'pronax'],\n",
       " 'Team iBUYPOWER': ['anger', 'Skadoodle', 'adreN', 'AZK', 'DaZeD'],\n",
       " 'LGB eSports': ['SKYTTEN', 'eksem', 'KRiMZ', 'dennis', 'olofm'],\n",
       " 'Recursive eSports': ['Happy', 'GMX', 'kennyS', 'Uzzziii', 'Maniac'],\n",
       " 'Xapso': ['ultra', 'centeks', 'cadiaN', 'aizy', 'robiin'],\n",
       " 'Reason Gaming': ['MSL', 'coloN', 'smF', 'EXR', 'LOMME']}"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_players[\"DreamHack/2013/Winter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player-Specific Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'b1t',\n",
       " 'image': 'B1t at Antwerp Major 2022 EU RMR.jpg',\n",
       " 'name': 'Валерій Євгенійович Ваховський',\n",
       " 'romanized_name': 'Valerij Jevghenijovych Vakhovsjkyj',\n",
       " 'birth_date': '2003-01-05',\n",
       " 'country': 'Ukraine',\n",
       " 'status': 'Active',\n",
       " 'years_active': '2019 – Present',\n",
       " 'team': 'Natus Vincere',\n",
       " 'role': 'entry',\n",
       " 'role2': 'awp',\n",
       " 'ids': 'B1T, B1t',\n",
       " 'csgo': 'y',\n",
       " 'faceit': 'b1t',\n",
       " 'vk': 'b1tcs',\n",
       " 'steam': '76561198246607476',\n",
       " 'instagram': 'b1tcsgo',\n",
       " 'esea': '2255709',\n",
       " 'twitter': 'b1tcs',\n",
       " 'twitch': 'b1tcs',\n",
       " 'team_history': ''}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_player_dict(\"b1t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME': 'S1mple',\n",
       " 'REGION': 'Ukraine',\n",
       " 'REAL NAME': 'Oleksandr Oleghovych Kostyljev',\n",
       " 'NATIONALITY': 'Ukraine',\n",
       " 'TEAM': 'Natus Vincere',\n",
       " 'AGE': '02/10/1997',\n",
       " 'WEAPON': 'AWP',\n",
       " 'MAJOR APPEARANCES': 0,\n",
       " 'EARNINGS': 1743186,\n",
       " 'LAST UPDATED': '09/04/2023'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_player(player_id, major_list, debug=True):\n",
    "    # parse player information\n",
    "    info_dict = fetch_player_dict(player_id)\n",
    "    if debug:\n",
    "        print(info_dict)\n",
    "    \n",
    "    # add name to dict\n",
    "    output_dict = dict()\n",
    "    output_dict[\"NAME\"] = info_dict.get(\"id\")\n",
    "    output_dict[\"REGION\"] = \"todo\"\n",
    "    output_dict[\"REAL NAME\"] = info_dict.get(\"romanized_name\", info_dict.get(\"name\"))\n",
    "    output_dict[\"NATIONALITY\"] = info_dict.get(\"country\")\n",
    "    output_dict[\"TEAM\"] = info_dict.get(\"team\")\n",
    "    output_dict[\"AGE\"] = info_dict.get(\"birth_date\")\n",
    "    #output_dict[\"AGE\"] = datetime.strptime(, \"%B %d %Y\").strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    # Get role\n",
    "    role_description = None\n",
    "    if \"Role\" in info_dict:\n",
    "        role_description = info_dict[\"Role\"]\n",
    "    elif \"Roles\" in info_dict:\n",
    "        role_description = info_dict[\"Roles\"]\n",
    "    \n",
    "    if role_description != None:\n",
    "        if \"AWPer\" in role_description:\n",
    "            output_dict[\"WEAPON\"] = \"AWP\"\n",
    "        elif \"Rifler\" in role_description:\n",
    "            output_dict[\"WEAPON\"] = \"AK47\"\n",
    "            \n",
    "            \n",
    "    # Get major appearances\n",
    "    try:\n",
    "        soup = fetch_page(player_name + \"/Results\")\n",
    "        event_elements = soup.find_all(\"tr\", {\"class\": \"valvemajor-highlighted\"})\n",
    "        event_name_list = [event.find(\"td\", {\"style\": \"text-align:left\"}).find(\"a\")[\"href\"] for event in event_elements]\n",
    "        event_name_list = [event for event in event_name_list if event in major_list]\n",
    "        output_dict[\"MAJOR APPEARANCES\"] = len(event_name_list)\n",
    "    except:\n",
    "        output_dict[\"MAJOR APPEARANCES\"] = 0\n",
    "    \n",
    "    if \"Approx. Total Winnings\" in info_dict:\n",
    "        output_dict[\"EARNINGS\"] = int(info_dict[\"Approx. Total Winnings\"].replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "    else:\n",
    "        output_dict[\"EARNINGS\"] = 0\n",
    "    \n",
    "    output_dict[\"LAST UPDATED\"] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    return output_dict\n",
    "\n",
    "#fetch_player(\"XANTARES\", \"Turkey\", MAJOR_LIST, debug=False)\n",
    "fetch_player(\"S1mple\", \"Ukraine\", MAJOR_LIST, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0d5f0697534b0e9e01166630207200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad17bf789b9489283571836c3154cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: list index out of range\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'players.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     playerdata\u001b[38;5;241m.\u001b[39mto_csv(CSV_FILE, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mbuild_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mbuild_df\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mplayerdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3549\u001b[0m )\n\u001b[1;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[1;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'players.csv'"
     ]
    }
   ],
   "source": [
    "def build_df():\n",
    "    # Get dataframe to werite to\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        playerdata = pd.read_csv(CSV_FILE)\n",
    "    else:\n",
    "        playerdata = pd.DataFrame(columns=COLUMNS)\n",
    "        \n",
    "    # Get list of all mayors\n",
    "    major_list = fetch_majors()\n",
    "\n",
    "    try:\n",
    "        for major_region, sub_regions in tqdm(REGIONS.items()):\n",
    "            for sub_region in tqdm(sub_regions, leave=False):\n",
    "                region_ids = fetch_ids(sub_region)[:1]\n",
    "                for player in tqdm(region_ids, leave=False):\n",
    "                    if not (playerdata[\"NAME\"].eq(player)).any():\n",
    "                        row_data = fetch_player(player, major_region, major_list)\n",
    "                        playerdata = pd.concat([playerdata, pd.DataFrame.from_records([row_data])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    \n",
    "    playerdata.to_csv(CSV_FILE, index=False)\n",
    "    return=(TODAY()-B2)/365\n",
    "\n",
    "build_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age(birthdate):\n",
    "    birthdate = datetime.strptime(birthdate, \"%d/%m/%Y\")\n",
    "    today = datetime.now()\n",
    "    age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "    return age\n",
    "\n",
    "def playerdata_postprocess(df):\n",
    "    columns = list(pd.read_csv(CSV_FILE).columns)\n",
    "    del columns[columns.index(\"TEAM\")]\n",
    "    df.dropna(inplace = True, subset = columns)\n",
    "    df.sort_values(by=[\"EARNINGS\"], ascending = False, inplace = True)\n",
    "    df[\"AGE\"] = [age(date) for date in df[\"AGE\"]]\n",
    "    df[\"REGION\"] = np.where(df[\"NATIONALITY\"].isin(MISLABELS), \"Europe\", df[\"REGION\"])\n",
    "    return df\n",
    "\n",
    "playerdata_post = playerdata_postprocess(pd.read_csv(CSV_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9a8b8ae70a43f490007944c8a454b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='REGION', index=(0, 1, 2), options=('Europe', 'Americas', 'As…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.ui_selector(sregion, sage, sweapon, smajors)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_selection(data, description):\n",
    "    unique_data = list(data.unique())\n",
    "    return widgets.SelectMultiple(\n",
    "        options=unique_data,\n",
    "        value=unique_data,\n",
    "        rows=len(unique_data),\n",
    "        description=description,\n",
    "        disabled=False)\n",
    "\n",
    "\n",
    "def generate_rangeslider(data, description):\n",
    "    return widgets.FloatRangeSlider(\n",
    "        value=[min(data), max(data)],\n",
    "        min=min(data),\n",
    "        max=max(data),\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='1',\n",
    ")\n",
    "\n",
    "region_selector = generate_selection(playerdata_post[\"REGION\"], \"REGION\")\n",
    "age_slider = generate_rangeslider(playerdata_post[\"AGE\"], \"AGE\")\n",
    "weapon_selector = generate_selection(playerdata_post[\"WEAPON\"], \"WEAPON\")\n",
    "majors_slider = generate_rangeslider(playerdata_post[\"MAJOR APPEARANCES\"], \"MAJOR APPEARANCES\")\n",
    "\n",
    "def ui_selector(sregion, sage, sweapon, smajors):\n",
    "    return playerdata_post.loc[(playerdata_post[\"REGION\"].isin(sregion)) &\n",
    "                               (playerdata_post[\"AGE\"] >= sage[0]) &\n",
    "                               (playerdata_post[\"AGE\"] <= sage[1]) &\n",
    "                               (playerdata_post[\"WEAPON\"].isin(sweapon)) &\n",
    "                               (playerdata_post[\"MAJOR APPEARANCES\"] >= smajors[0]) &\n",
    "                               (playerdata_post[\"MAJOR APPEARANCES\"] <= smajors[1])\n",
    "                               ]\n",
    "    \n",
    "interact(ui_selector, sregion = region_selector, sage = age_slider, sweapon = weapon_selector, smajors = majors_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
