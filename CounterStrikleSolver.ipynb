{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counter Strikle Webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Daniël Vermaas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes liquidpedia (https://liquipedia.net/counterstrike/Main_Page), in order to make counter strikle (https://blast.tv/counter-strikle) puzzle-solving easier. Before using the notebook, please read the Liquidpedia ToS about API usage: https://liquipedia.net/api-terms-of-use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import mwparserfromhell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T18:36:01.813737100Z",
     "start_time": "2023-05-18T18:36:01.803617600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "HEADERS = {\"User-Agent\": \"Counter-Strikle-Bot\",\"Accept-Encoding\": \"gzip\"}\n",
    "BASE_URL = \"https://liquipedia.net/counterstrike/api.php?\"\n",
    "QUERY_COOLDOWN = 4\n",
    "CSV_FILE = \"players.csv\"\n",
    "REGIONS = {\n",
    "    \"Europe\" : [\"Europe\", \"CIS\"],\n",
    "    \"Americas\" : [\"North America\", \"South America\"],\n",
    "    \"Asia-Pacific\" : [\"Oceania\", \"Asia\"],\n",
    "}\n",
    "COLUMNS = [\n",
    "    \"NAME\",\n",
    "    \"REAL NAME\",\n",
    "    \"REGION\",\n",
    "    \"NATIONALITY\",\n",
    "    \"TEAM\",\n",
    "    \"AGE\",\n",
    "    \"WEAPON\",\n",
    "    \"MAJOR APPEARANCES\",\n",
    "    \"EARNINGS\",\n",
    "    \"LAST UPDATED\"\n",
    "]\n",
    "UNWANTED_STRINGS = [\n",
    "    \"Players\",\n",
    "    \"Teams\",\n",
    "    \"Tournaments\",\n",
    "    \"Casters\",\n",
    "    \"Countries\",\n",
    "    \"Asia\",\n",
    "    \"CIS\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T21:07:09.947560100Z",
     "start_time": "2023-05-18T21:07:09.940941900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MediaWiki API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# API call function\n",
    "def fetch_page(page, cooldown=0):\n",
    "    url =  f\"{BASE_URL}action=parse&format=json&page={page}\"\n",
    "    response = requests.get(url, HEADERS)\n",
    "    page_html = response.json()['parse']['text']['*']\n",
    "    soup = BeautifulSoup(page_html,features=\"lxml\")\n",
    "    time.sleep(cooldown)\n",
    "    return soup\n",
    "\n",
    "def query_page(page, rvsection, cooldown=QUERY_COOLDOWN):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": page,\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"*\",\n",
    "        \"rvsection\": rvsection,\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    data = response.json()\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    page_id = next(iter(pages))\n",
    "    page = pages[page_id]\n",
    "    wikicode = mwparserfromhell.parse(page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"])\n",
    "    time.sleep(cooldown)\n",
    "    return wikicode"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T21:07:23.784616800Z",
     "start_time": "2023-05-18T21:07:23.776802500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Country to Region Map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "'Europe'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_region_dict():\n",
    "    country_region_dict = {}\n",
    "    with open(\"regions.json\", \"r\") as file:\n",
    "        region_dict = json.load(file)\n",
    "    for region, countries in region_dict.items():\n",
    "            for country in countries:\n",
    "                country_region_dict[country] = region\n",
    "    return country_region_dict\n",
    "\n",
    "REGION_DICT = build_region_dict()\n",
    "REGION_DICT.get(\"Turkey\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T21:08:03.458932900Z",
     "start_time": "2023-05-18T21:08:03.452039200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T17:15:23.579211200Z",
     "start_time": "2023-05-18T17:15:19.222774700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fetches list of all concluded majors (checks hltv awards) \n",
    "def fetch_majors():\n",
    "    wikicode = query_page(\"Majors\", 8)\n",
    "    links = wikicode.filter_wikilinks()\n",
    "    links = [link.split('|')[0].replace('[[', '') for link in links]\n",
    "    return links\n",
    "\n",
    "MAJOR_LIST = fetch_majors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T17:12:06.762140400Z",
     "start_time": "2023-05-18T17:12:02.426299900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'ropz',\n 'image': 'Ropz at Antwerp Major EU RMR.jpg',\n 'name': 'Robin Kool',\n 'birth_date': '1999-12-22',\n 'country': 'Estonia',\n 'status': 'Active',\n 'years_active': '2015 – Present',\n 'team': 'FaZe Clan',\n 'role': 'lurk',\n 'csgo': 'y',\n 'twitter': 'ropz',\n 'facebook': 'ropzicle',\n 'instagram': 'ropzicle',\n 'youtube': 'c/Ropz',\n 'twitch': 'ropz',\n 'esea': '1042223',\n 'faceit': 'ropz',\n 'steam': '76561197991272318',\n 'team_history': ''}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetches all player data and puts it in dict\n",
    "def fetch_player_dict(player_id):\n",
    "    wikicode = query_page(player_id, 0)\n",
    "    infobox = wikicode.filter_templates(matches=\"Infobox player\")[0]\n",
    "    infobox_dict = {}\n",
    "    for param in infobox.params:\n",
    "        value = mwparserfromhell.parse(param.value.strip_code()).strip()\n",
    "        infobox_dict[param.name.strip()] = str(value)\n",
    "    return infobox_dict\n",
    "\n",
    "# Fetches all player ids\n",
    "def fetch_players():\n",
    "    url = f\"{BASE_URL}action=query&list=categorymembers&cmtitle=Category:Players&cmlimit=max&format=json\"\n",
    "    results = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        time.sleep(QUERY_COOLDOWN)\n",
    "        data = json.loads(response.text)\n",
    "        pages = data[\"query\"][\"categorymembers\"]\n",
    "        results.extend(pages)\n",
    "\n",
    "        if \"continue\" not in data:\n",
    "            break\n",
    "\n",
    "        cont = data[\"continue\"]\n",
    "        cmcontinue = cont[\"cmcontinue\"]\n",
    "        url = f\"{url}&cmcontinue={cmcontinue}\"\n",
    "    return results\n",
    "\n",
    "fetch_player_dict(\"ropz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T21:20:07.476924100Z",
     "start_time": "2023-05-18T21:18:44.817045100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Ninjas in Pyjamas': ('f0rest', 'GeT_RiGhT', 'Xizt', 'Fifflaren', 'friberg'),\n 'n!faculty': ('gla1ve', 'karrigan', 'cajunb', 'Pimp', 'raalz'),\n 'SK Gaming': ('pita', 'twist', 'xelos', 'Delpan', 'MODDII'),\n 'Copenhagen Wolves': ('FeTiSh', 'dupreeh', 'Xyp9x', 'device', 'Nico'),\n 'Universal Soldiers': ('TaZ', 'NEO', 'pashaBiceps', 'Snax', 'byali'),\n 'Natus Vincere': ('Zeus', 'starix', 'ceh9', 'seized', 'kibaken'),\n 'Astana Dragons': ('ANGE1', 'Dosia', 'AdreN', 'markeloff', 'kUcheR'),\n 'compLexity Gaming': ('Hiko', 'seang@res', 'Semphis', 'swag', 'n0thing'),\n 'VeryGames': ('Ex6TenZ', 'NBK-', 'SmithZz', 'ScreaM', 'shox'),\n 'Clan-Mystik': ('HaRts', 'ioRek', 'kioShiMa', 'KQLY', 'apEX'),\n 'Fnatic': ('JW', 'flusha', 'schneider', 'Devilwalk', 'pronax'),\n 'Team iBUYPOWER': ('anger', 'Skadoodle', 'adreN', 'AZK', 'DaZeD'),\n 'LGB eSports': ('SKYTTEN', 'eksem', 'KRiMZ', 'dennis', 'olofm'),\n 'Recursive eSports': ('Happy', 'GMX', 'kennyS', 'Uzzziii', 'Maniac'),\n 'Xapso': ('ultra', 'centeks', 'cadiaN', 'aizy', 'robiin'),\n 'Reason Gaming': ('MSL', 'coloN', 'smF', 'EXR', 'LOMME')}"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_major_players():\n",
    "    major_dict = {}\n",
    "    for major in fetch_majors():\n",
    "        wikicode = query_page(major, \"5\")\n",
    "        teams_dict = {}\n",
    "        for template in wikicode.filter_templates(matches=r\"\\bTeamCard\\b\"):\n",
    "            if template.name.strip() == \"TeamCard\":\n",
    "                # skip showmatches\n",
    "                if not template.has(\"qualifier\"):\n",
    "                    continue\n",
    "                if not template.has(\"p1\"):\n",
    "                    continue\n",
    "                team = template.get(\"team\").value.strip()\n",
    "                players = tuple(template.get(f\"p{i}\").value.strip() for i in range(1, 6))\n",
    "                teams_dict[team] = players\n",
    "        major_dict[major] = teams_dict\n",
    "    return major_dict\n",
    "\n",
    "major_players = fetch_major_players()\n",
    "major_players[\"DreamHack/2013/Winter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Heroic': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B27B4C0>,\n 'Copenhagen Flames': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B27B3D0>,\n 'BIG': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B27BC40>,\n 'Cloud9': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B27A5C0>,\n 'FURIA Esports': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B68C7C0>,\n 'FaZe Clan': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B68C040>,\n 'Ninjas in Pyjamas': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B68C130>,\n 'Natus Vincere': <generator object fetch_major_players.<locals>.<genexpr> at 0x000001B62B68C220>}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_players.get(\"PGL/2022/Antwerp\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:28:34.039985300Z",
     "start_time": "2023-05-18T17:28:34.034959300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player-Specific Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T18:36:24.615197900Z",
     "start_time": "2023-05-18T18:36:19.834102400Z"
    }
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFeatureNotFound\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 35\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output_dict\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m#fetch_player(\"XANTARES\", MAJOR_LIST)\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m \u001B[43mfetch_player\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mS1mple\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMAJOR_LIST\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[54], line 20\u001B[0m, in \u001B[0;36mfetch_player\u001B[1;34m(player_id, major_list)\u001B[0m\n\u001B[0;32m     17\u001B[0m     output_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWEAPON\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAK47\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Get major appearances\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m soup \u001B[38;5;241m=\u001B[39m \u001B[43mfetch_page\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mS1mple/Results\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m     soup \u001B[38;5;241m=\u001B[39m fetch_page(output_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNAME\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Results\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[53], line 6\u001B[0m, in \u001B[0;36mfetch_page\u001B[1;34m(page, cooldown)\u001B[0m\n\u001B[0;32m      4\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url, HEADERS)\n\u001B[0;32m      5\u001B[0m page_html \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparse\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 6\u001B[0m soup \u001B[38;5;241m=\u001B[39m \u001B[43mBeautifulSoup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpage_html\u001B[49m\u001B[43m,\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlxml\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(cooldown)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m soup\n",
      "File \u001B[1;32m~\\Documents\\Repos\\Counter-Strikle\\venv\\Lib\\site-packages\\bs4\\__init__.py:250\u001B[0m, in \u001B[0;36mBeautifulSoup.__init__\u001B[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001B[0m\n\u001B[0;32m    248\u001B[0m     builder_class \u001B[38;5;241m=\u001B[39m builder_registry\u001B[38;5;241m.\u001B[39mlookup(\u001B[38;5;241m*\u001B[39mfeatures)\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m builder_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 250\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m FeatureNotFound(\n\u001B[0;32m    251\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a tree builder with the features you \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    252\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequested: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m. Do you need to install a parser library?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    253\u001B[0m             \u001B[38;5;241m%\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(features))\n\u001B[0;32m    255\u001B[0m \u001B[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001B[39;00m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001B[39;00m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# with the remaining **kwargs.\u001B[39;00m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m builder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mFeatureNotFound\u001B[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "def fetch_player(player_id, major_list):\n",
    "    # parse player information\n",
    "    info_dict = fetch_player_dict(player_id)\n",
    "    \n",
    "    # add name to dict\n",
    "    output_dict = dict()\n",
    "    output_dict[\"NAME\"] = info_dict.get(\"id\")\n",
    "    output_dict[\"REGION\"] = \"todo\"\n",
    "    output_dict[\"REAL NAME\"] = info_dict.get(\"romanized_name\", info_dict.get(\"name\"))\n",
    "    output_dict[\"NATIONALITY\"] = info_dict.get(\"country\")\n",
    "    output_dict[\"TEAM\"] = info_dict.get(\"team\")\n",
    "    output_dict[\"AGE\"] = info_dict.get(\"birth_date\")\n",
    "    roles = [info_dict.get(\"role\"), info_dict.get(\"role2\")]\n",
    "    if \"awp\" in roles:\n",
    "        output_dict[\"WEAPON\"] = \"AWP\"\n",
    "    else:\n",
    "        output_dict[\"WEAPON\"] = \"AK47\"\n",
    "            \n",
    "    # Get major appearances\n",
    "    soup = fetch_page(\"S1mple/Results\")\n",
    "    try:\n",
    "        soup = fetch_page(output_dict[\"NAME\"] + \"/Results\")\n",
    "        print(soup)\n",
    "        event_elements = soup.find_all(\"tr\", {\"class\": \"valvemajor-highlighted\"})\n",
    "        event_name_list = [event.find(\"td\", {\"style\": \"text-align:left\"}).find(\"a\")[\"href\"] for event in event_elements]\n",
    "        event_name_list = [event for event in event_name_list if event in major_list]\n",
    "        output_dict[\"MAJOR APPEARANCES\"] = len(event_name_list)\n",
    "    except:\n",
    "        output_dict[\"MAJOR APPEARANCES\"] = 0\n",
    "    \n",
    "    output_dict[\"LAST UPDATED\"] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    return output_dict\n",
    "\n",
    "#fetch_player(\"XANTARES\", MAJOR_LIST)\n",
    "fetch_player(\"S1mple\", MAJOR_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'cadiaN',\n 'image': 'CadiaN at BLAST Paris Major 2023 EU RMR.jpeg',\n 'name': 'Casper Møller',\n 'birth_date': '1995-06-26',\n 'country': 'Denmark',\n 'team': 'Heroic',\n 'status': 'Active',\n 'years_active': '2011 – Present',\n 'role': 'igl',\n 'role2': 'awp',\n 'ids': 'cadiii, Cadian',\n 'css': 'y',\n 'csgo': 'y',\n 'twitch': 'cadian',\n 'twitter': 'caspercadiaN',\n 'facebook': 'caspercadiaN',\n 'steam': '76561198004115516',\n 'esea': '388062',\n 'faceit': 'cadiaN',\n 'instagram': 'cadiancs',\n 'team_history': 'Counter-Strike: Source\\n\\nCounter-Strike: Global Offensive'}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_player_dict(\"CadiaN\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T17:18:58.137334800Z",
     "start_time": "2023-05-18T17:18:53.815840500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df():\n",
    "    # Get dataframe to werite to\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        playerdata = pd.read_csv(CSV_FILE)\n",
    "    else:\n",
    "        playerdata = pd.DataFrame(columns=COLUMNS)\n",
    "        \n",
    "    # Get list of all mayors\n",
    "    major_list = fetch_majors()\n",
    "\n",
    "    try:\n",
    "        for major_region, sub_regions in tqdm(REGIONS.items()):\n",
    "            for sub_region in tqdm(sub_regions, leave=False):\n",
    "                region_ids = fetch_ids(sub_region)[:1]\n",
    "                for player in tqdm(region_ids, leave=False):\n",
    "                    if not (playerdata[\"NAME\"].eq(player)).any():\n",
    "                        row_data = fetch_player(player, major_region, major_list)\n",
    "                        playerdata = pd.concat([playerdata, pd.DataFrame.from_records([row_data])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    \n",
    "    playerdata.to_csv(CSV_FILE, index=False)\n",
    "    return=(TODAY()-B2)/365\n",
    "\n",
    "build_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age(birthdate):\n",
    "    birthdate = datetime.strptime(birthdate, \"%d/%m/%Y\")\n",
    "    today = datetime.now()\n",
    "    age = today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "    return age\n",
    "\n",
    "def playerdata_postprocess(df):\n",
    "    columns = list(pd.read_csv(CSV_FILE).columns)\n",
    "    del columns[columns.index(\"TEAM\")]\n",
    "    df.dropna(inplace = True, subset = columns)\n",
    "    df.sort_values(by=[\"EARNINGS\"], ascending = False, inplace = True)\n",
    "    df[\"AGE\"] = [age(date) for date in df[\"AGE\"]]\n",
    "    df[\"REGION\"] = np.where(df[\"NATIONALITY\"].isin(MISLABELS), \"Europe\", df[\"REGION\"])\n",
    "    return df\n",
    "\n",
    "playerdata_post = playerdata_postprocess(pd.read_csv(CSV_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_selection(data, description):\n",
    "    unique_data = list(data.unique())\n",
    "    return widgets.SelectMultiple(\n",
    "        options=unique_data,\n",
    "        value=unique_data,\n",
    "        rows=len(unique_data),\n",
    "        description=description,\n",
    "        disabled=False)\n",
    "\n",
    "\n",
    "def generate_rangeslider(data, description):\n",
    "    return widgets.FloatRangeSlider(\n",
    "        value=[min(data), max(data)],\n",
    "        min=min(data),\n",
    "        max=max(data),\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='1',\n",
    ")\n",
    "\n",
    "region_selector = generate_selection(playerdata_post[\"REGION\"], \"REGION\")\n",
    "age_slider = generate_rangeslider(playerdata_post[\"AGE\"], \"AGE\")\n",
    "weapon_selector = generate_selection(playerdata_post[\"WEAPON\"], \"WEAPON\")\n",
    "majors_slider = generate_rangeslider(playerdata_post[\"MAJOR APPEARANCES\"], \"MAJOR APPEARANCES\")\n",
    "\n",
    "def ui_selector(sregion, sage, sweapon, smajors):\n",
    "    return playerdata_post.loc[(playerdata_post[\"REGION\"].isin(sregion)) &\n",
    "                               (playerdata_post[\"AGE\"] >= sage[0]) &\n",
    "                               (playerdata_post[\"AGE\"] <= sage[1]) &\n",
    "                               (playerdata_post[\"WEAPON\"].isin(sweapon)) &\n",
    "                               (playerdata_post[\"MAJOR APPEARANCES\"] >= smajors[0]) &\n",
    "                               (playerdata_post[\"MAJOR APPEARANCES\"] <= smajors[1])\n",
    "                               ]\n",
    "    \n",
    "interact(ui_selector, sregion = region_selector, sage = age_slider, sweapon = weapon_selector, smajors = majors_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
