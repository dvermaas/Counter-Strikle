{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counter Strikle Webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following code scrapes liquidpedia (https://liquipedia.net/counterstrike/Main_Page), in order to make counter strikle (https://blast.tv/counter-strikle) puzzle-solving easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> URL's of the target website, together with the regions that will be mined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS = [\"Europe\", \"CIS\", \"Americas\", \"Oceania\", \"Eastern_%26_Southern_Asia\"]\n",
    "URL = \"https://liquipedia.net/counterstrike\"\n",
    "REGION_URL = URL + \"/Portal:Players\"\n",
    "CSV_FILE = \"players.csv\"\n",
    "COLUMNS = [\"NAME\", \"REAL NAME\", \"REGION\", \"NATIONALITY\", \"TEAM\", \"AGE\", \"WEAPON\", \n",
    "           \"MAJOR APPEARANCES\", \"EARNINGS\", \"LAST UPDATED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Major aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In order to calculate major appearances all majors are scraped in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/counterstrike/Intel_Extreme_Masters/2022/Rio',\n",
       " '/counterstrike/PGL/2022/Antwerp',\n",
       " '/counterstrike/PGL/2021/Stockholm',\n",
       " '/counterstrike/ESL/One/2020/Rio',\n",
       " '/counterstrike/StarLadder/2019/Major',\n",
       " '/counterstrike/Intel_Extreme_Masters/Season_XIII/World_Championship',\n",
       " '/counterstrike/FACEIT/2018/Major',\n",
       " '/counterstrike/ELEAGUE/2018/Major',\n",
       " '/counterstrike/PGL/2017/Krakow',\n",
       " '/counterstrike/ELEAGUE/2017/Major',\n",
       " '/counterstrike/ESL/One/2016/Cologne',\n",
       " '/counterstrike/MLG/2016/Columbus',\n",
       " '/counterstrike/DreamHack/2015/Cluj-Napoca',\n",
       " '/counterstrike/ESL/One/2015/Cologne',\n",
       " '/counterstrike/ESL/One/2015/Katowice',\n",
       " '/counterstrike/DreamHack/2014/Winter',\n",
       " '/counterstrike/ESL/One/2014/Cologne',\n",
       " '/counterstrike/ESL/Major_Series_One/2014/Katowice',\n",
       " '/counterstrike/DreamHack/2013/Winter']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(URL + \"/Majors\")\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "event_elements = soup.find_all(\"div\", {\"class\": \"divRow tournament-card-premier\"})\n",
    "major_list = [event.find(\"b\").find(\"a\")[\"href\"] for event in event_elements]\n",
    "major_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining All Player Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In order to get to player profiles the gamertags need to be scraped first, given that these are used for linking to the player specific pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all players from certain region\n",
    "def fetch_region_players(region):\n",
    "    page = requests.get(REGION_URL + \"/\" + region)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    elements = [item.find_all(\"a\")[1] for item in soup.find_all(\"td\")]\n",
    "    name_dict = [element[\"title\"] for element in elements]\n",
    "    return name_dict\n",
    "\n",
    "regional_data = dict()\n",
    "for region in REGIONS:\n",
    "    regional_data[region] = fetch_region_players(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Player Specific Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using the gamertags it is now possible to get the required counter-strikle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_player(player_name, region, ratelimit=60, debug=False):\n",
    "    # pull player profile\n",
    "    page = requests.get(URL + \"/\" + player_name)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    time.sleep(ratelimit)\n",
    "    output_dict = dict()\n",
    "    \n",
    "    # parse player information\n",
    "    info_list = soup.find_all(\"div\", {\"class\": \"infobox-cell-2\"})\n",
    "    info_dict = {info_list[i].text[:-1] : info_list[i+1].text for i in range(0, len(info_list),2)}\n",
    "    if debug:\n",
    "        print(info_dict)\n",
    "    # add name to dict\n",
    "    output_dict[\"NAME\"] = player_name\n",
    "    output_dict[\"REGION\"] = region\n",
    "    \n",
    "    # replace name with romanised name if needed\n",
    "    if \"Romanized Name\" in info_dict:\n",
    "        output_dict[\"REAL NAME\"] = info_dict[\"Romanized Name\"]\n",
    "    else:\n",
    "        output_dict[\"REAL NAME\"] = info_dict[\"Name\"]\n",
    "    \n",
    "    # get nationality\n",
    "    if \"Nationality\" in info_dict:\n",
    "        output_dict[\"NATIONALITY\"] = info_dict[\"Nationality\"][1:]\n",
    "    \n",
    "    # get team\n",
    "    if \"Team\"  in info_dict:\n",
    "        output_dict[\"TEAM\"] = info_dict[\"Team\"]\n",
    "    \n",
    "    # Get age\n",
    "    if \"Born\" in info_dict:\n",
    "        try:\n",
    "            output_dict[\"AGE\"] = datetime.strptime(info_dict[\"Born\"][:-9].replace(\",\", \"\"), \"%B %d %Y\").strftime(\"%d/%m/%Y\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Get role\n",
    "    if \"Role\" in info_dict:\n",
    "        if \"AWPer\" in info_dict[\"Role\"]:\n",
    "            output_dict[\"WEAPON\"] = \"AWP\"\n",
    "        else:\n",
    "            output_dict[\"WEAPON\"] = \"AK47\"\n",
    "    elif \"Roles\" in info_dict:\n",
    "        if \"AWPer\" in info_dict[\"Roles\"]:\n",
    "            output_dict[\"WEAPON\"] = \"AWP\"\n",
    "        else:\n",
    "            output_dict[\"WEAPON\"] = \"AK47\"\n",
    "            \n",
    "    # Get major appearances\n",
    "    page = requests.get(URL + \"/\" + player_name + \"/Results\")\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    event_elements = soup.find_all(\"tr\", {\"class\": \"valvemajor-highlighted\"})\n",
    "    event_name_list = [event.find(\"td\", {\"style\": \"text-align:left\"}).find(\"a\")[\"href\"] for event in event_elements]\n",
    "    event_name_list = [event for event in event_name_list if event in major_list]\n",
    "    output_dict[\"MAJOR APPEARANCES\"] = len(event_name_list)\n",
    "    \n",
    "    if \"Approx. Total Winnings\" in info_dict:\n",
    "        output_dict[\"EARNINGS\"] = info_dict[\"Approx. Total Winnings\"]\n",
    "    else:\n",
    "        output_dict[\"EARNINGS\"] = \"0$\"\n",
    "    \n",
    "    output_dict[\"LAST UPDATED\"] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    return output_dict\n",
    "    \n",
    "#fetch_player(\"MingSir\", \"Eastern_%26_Southern_Asia\", ratelimit=0, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcca609d2ca451c84a1320efa0d3bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b7181f019e4cd59b6acb068512a25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-175870541ede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mrow_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mplayerdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayerdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mplayerdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCSV_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m             )\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    360\u001b[0m         )\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mlibwriters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mpandas\\_libs\\writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "if os.path.exists(CSV_FILE):\n",
    "    playerdata = pd.read_csv(CSV_FILE)\n",
    "else:\n",
    "    playerdata = pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "for region in tqdm(REGIONS):\n",
    "    for player in tqdm(regional_data[region], leave=False):\n",
    "        if not (playerdata[\"NAME\"].eq(player)).any():\n",
    "            #print(player)\n",
    "            row_data = fetch_player(player, region) \n",
    "            playerdata = playerdata.append(row_data, ignore_index=True)\n",
    "playerdata.to_csv(CSV_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "playerdata.to_csv(CSV_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
